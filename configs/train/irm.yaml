# @package _global_

defaults:
  - /data: synthetic
  - /envs: daily
  - /model: irm
  - /eval: daily
  - /logging: default
  - _self_

train:
  steps: 150000
  batch_size: 128
  grad_clip: 1.0
  seed: 0
  pretrain_steps: 20000
  irm_ramp_steps: 10000
  eval_interval: 1000
  checkpoint_topk: 3
  max_trade_warning: 50.0

loss:
  name: cvar
  cvar_alpha: 0.95

optimizer:
  name: adamw
  lr: 1.0e-4
  weight_decay: 1.0e-6

scheduler:
  name: cosine
  warmup_steps: 1000

logging:
  log_interval: 100
  eval_interval: 1000

irm:
  lambda_init: 0.0
  lambda_target: 1.0
  ramp_steps: 10000
