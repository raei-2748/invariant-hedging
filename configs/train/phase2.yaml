# @package _global_

defaults:
  - /data: synthetic
  - /envs: daily
  - /model: hirm_head
  - /eval: daily
  - /logging: default
  - _self_

train:
  steps: 150000
  batch_size: 128
  grad_clip: 1.0
  seed: 0
  eval_interval: 1000
  checkpoint_topk: 3
  max_trade_warning_factor: 1.0

loss:
  name: cvar
  cvar_alpha: 0.95

optimizer:
  name: adamw
  lr: 1.0e-4
  weight_decay: 1.0e-6

scheduler:
  name: cosine

logging:
  log_interval: 200
  eval_interval: 1000

irm:
  enabled: true
  type: cosine
  lambda: 0.01
  normalize: l2
  eps: 1.0e-12
  env_min: 2
  freeze_backbone: true
  logging:
    log_irm_grads: true

hydra:
  sweeper:
    params:
      irm.lambda: 0.01,0.1
