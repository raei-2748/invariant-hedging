# @package _global_

defaults:
  - _self_
  - override /data: synthetic
  - override /envs: daily
  - override /model: hirm_head
  - override /eval: daily
  - override /logging: default

train:
  steps: 150000
  batch_size: 128
  grad_clip: 1.0
  seed: 0
  eval_interval: 1000
  checkpoint_topk: 3
  max_trade_warning_factor: 1.0
  envs: [low, med, high_slim]
  env_weights: [0.45, 0.45, 0.10]
  lambda_grid: [0.1, 1.0, 10.0, 100.0]

loss:
  name: cvar
  cvar_alpha: 0.95

optimizer:
  name: adamw
  lr: 1.0e-4
  weight_decay: 1.0e-6

scheduler:
  name: cosine

logging:
  log_interval: 200
  eval_interval: 1000

irm:
  enabled: true
  type: cosine
  lambda: 0.01
  normalize: l2
  eps: 1.0e-12
  env_min: 2
  freeze_backbone: true
  logging:
    log_irm_grads: true

hydra:
  sweeper:
    params:
      irm.lambda: 0.01,0.1
